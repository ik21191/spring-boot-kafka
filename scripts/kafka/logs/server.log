[2025-04-13 18:40:06,520] INFO Reading configuration from: D:\MyProject\Software_In_Use\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:40:06,520] WARN \tmp\zookeeper is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:40:06,526] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:40:06,526] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:40:06,526] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-04-13 18:40:06,526] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-04-13 18:40:06,526] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-04-13 18:40:06,526] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2025-04-13 18:40:06,536] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2025-04-13 18:40:06,567] INFO Reading configuration from: D:\MyProject\Software_In_Use\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:40:06,567] WARN \tmp\zookeeper is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:40:06,567] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:40:06,567] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:40:06,567] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2025-04-13 18:40:06,578] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-04-13 18:40:06,598] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,598] INFO Server environment:host.name=LENOVO.mshome.net (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,598] INFO Server environment:java.version=17.0.12 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,598] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,598] INFO Server environment:java.home=C:\Program Files\Java\jdk-17 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,609] INFO Server environment:java.class.path=D:\MyProject\Software_In_Use\kafka\libs\activation-1.1.1.jar;D:\MyProject\Software_In_Use\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\argparse4j-0.7.0.jar;D:\MyProject\Software_In_Use\kafka\libs\audience-annotations-0.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\commons-cli-1.4.jar;D:\MyProject\Software_In_Use\kafka\libs\commons-lang3-3.8.1.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-api-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-file-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-json-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-mirror-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-mirror-client-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-runtime-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-transforms-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\hk2-api-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\hk2-locator-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\hk2-utils-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-annotations-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-core-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-databind-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-module-scala_2.12-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.inject-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\MyProject\Software_In_Use\kafka\libs\javassist-3.22.0-CR2.jar;D:\MyProject\Software_In_Use\kafka\libs\javassist-3.26.0-GA.jar;D:\MyProject\Software_In_Use\kafka\libs\javax.servlet-api-3.1.0.jar;D:\MyProject\Software_In_Use\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\MyProject\Software_In_Use\kafka\libs\jaxb-api-2.3.0.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-client-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-common-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-container-servlet-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-hk2-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-media-jaxb-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-server-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jopt-simple-5.0.4.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-clients-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-scala_2.12-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-tools-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-javadoc.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-javadoc.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-scaladoc.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-scaladoc.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-sources.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-sources.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test-sources.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test-sources.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\log4j-1.2.17.jar;D:\MyProject\Software_In_Use\kafka\libs\lz4-java-1.7.1.jar;D:\MyProject\Software_In_Use\kafka\libs\maven-artifact-3.6.3.jar;D:\MyProject\Software_In_Use\kafka\libs\metrics-core-2.2.0.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-codec-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-common-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-handler-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-transport-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\MyProject\Software_In_Use\kafka\libs\paranamer-2.8.jar;D:\MyProject\Software_In_Use\kafka\libs\plexus-utils-3.2.1.jar;D:\MyProject\Software_In_Use\kafka\libs\reflections-0.9.12.jar;D:\MyProject\Software_In_Use\kafka\libs\rocksdbjni-5.18.3.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-collection-compat_2.12-2.1.3.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-java8-compat_2.12-0.9.0.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-library-2.12.10.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-logging_2.12-3.9.2.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-reflect-2.12.10.jar;D:\MyProject\Software_In_Use\kafka\libs\slf4j-api-1.7.30.jar;D:\MyProject\Software_In_Use\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\MyProject\Software_In_Use\kafka\libs\snappy-java-1.1.7.3.jar;D:\MyProject\Software_In_Use\kafka\libs\validation-api-2.0.1.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\zookeeper-3.5.7.jar;D:\MyProject\Software_In_Use\kafka\libs\zookeeper-jute-3.5.7.jar;D:\MyProject\Software_In_Use\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,609] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-17\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Player\bin\;D:\Study\Software\oracle_WINDOWS.X64_193000_db_home\bin;C:\Users\imran\Downloads\WINDOWS.X64_193000_db_home\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-17\bin;D:\Study\apache-maven-3.8.4\bin;C:\Program Files\Kubernetes\Minikube;C:\Program Files\Docker\Docker\resources\bin;D:\Study\Software\helm-v3.14.0-windows-amd64\windows-amd64;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Go\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\imran\AppData\Local\Microsoft\WindowsApps;C:\Users\imran\AppData\Local\Google\Cloud SDK\google-cloud-sdk\bin;C:\Users\imran\AppData\Local\Microsoft\WinGet\Links;C:\Users\imran\go\bin;C:\Users\imran\AppData\Local\Programs\Microsoft VS Code\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,609] INFO Server environment:java.io.tmpdir=C:\Users\imran\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,609] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,609] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,609] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,609] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,609] INFO Server environment:user.name=imran (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,609] INFO Server environment:user.home=C:\Users\imran (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,609] INFO Server environment:user.dir=D:\MyProject\Software_In_Use (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,609] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,609] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,614] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,619] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,619] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,619] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir \tmp\zookeeper\version-2 snapdir \tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:40:06,758] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-04-13 18:40:06,766] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-04-13 18:40:06,774] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-04-13 18:40:06,814] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2025-04-13 18:40:06,838] INFO Reading snapshot \tmp\zookeeper\version-2\snapshot.111 (org.apache.zookeeper.server.persistence.FileSnap)
[2025-04-13 18:40:06,899] INFO Snapshotting: 0x120 to \tmp\zookeeper\version-2\snapshot.120 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-04-13 18:40:06,955] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2025-04-13 18:40:35,024] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-04-13 18:40:35,797] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-04-13 18:40:35,918] INFO starting (kafka.server.KafkaServer)
[2025-04-13 18:40:35,920] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-04-13 18:40:35,957] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-04-13 18:40:35,992] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,992] INFO Client environment:host.name=LENOVO.mshome.net (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,993] INFO Client environment:java.version=17.0.12 (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,993] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,994] INFO Client environment:java.home=C:\Program Files\Java\jdk-17 (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,995] INFO Client environment:java.class.path=D:\MyProject\Software_In_Use\kafka\libs\activation-1.1.1.jar;D:\MyProject\Software_In_Use\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\argparse4j-0.7.0.jar;D:\MyProject\Software_In_Use\kafka\libs\audience-annotations-0.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\commons-cli-1.4.jar;D:\MyProject\Software_In_Use\kafka\libs\commons-lang3-3.8.1.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-api-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-file-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-json-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-mirror-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-mirror-client-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-runtime-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-transforms-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\hk2-api-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\hk2-locator-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\hk2-utils-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-annotations-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-core-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-databind-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-module-scala_2.12-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.inject-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\MyProject\Software_In_Use\kafka\libs\javassist-3.22.0-CR2.jar;D:\MyProject\Software_In_Use\kafka\libs\javassist-3.26.0-GA.jar;D:\MyProject\Software_In_Use\kafka\libs\javax.servlet-api-3.1.0.jar;D:\MyProject\Software_In_Use\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\MyProject\Software_In_Use\kafka\libs\jaxb-api-2.3.0.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-client-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-common-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-container-servlet-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-hk2-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-media-jaxb-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-server-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jopt-simple-5.0.4.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-clients-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-scala_2.12-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-tools-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-javadoc.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-javadoc.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-scaladoc.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-scaladoc.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-sources.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-sources.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test-sources.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test-sources.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\log4j-1.2.17.jar;D:\MyProject\Software_In_Use\kafka\libs\lz4-java-1.7.1.jar;D:\MyProject\Software_In_Use\kafka\libs\maven-artifact-3.6.3.jar;D:\MyProject\Software_In_Use\kafka\libs\metrics-core-2.2.0.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-codec-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-common-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-handler-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-transport-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\MyProject\Software_In_Use\kafka\libs\paranamer-2.8.jar;D:\MyProject\Software_In_Use\kafka\libs\plexus-utils-3.2.1.jar;D:\MyProject\Software_In_Use\kafka\libs\reflections-0.9.12.jar;D:\MyProject\Software_In_Use\kafka\libs\rocksdbjni-5.18.3.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-collection-compat_2.12-2.1.3.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-java8-compat_2.12-0.9.0.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-library-2.12.10.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-logging_2.12-3.9.2.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-reflect-2.12.10.jar;D:\MyProject\Software_In_Use\kafka\libs\slf4j-api-1.7.30.jar;D:\MyProject\Software_In_Use\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\MyProject\Software_In_Use\kafka\libs\snappy-java-1.1.7.3.jar;D:\MyProject\Software_In_Use\kafka\libs\validation-api-2.0.1.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\zookeeper-3.5.7.jar;D:\MyProject\Software_In_Use\kafka\libs\zookeeper-jute-3.5.7.jar;D:\MyProject\Software_In_Use\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,996] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-17\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Player\bin\;D:\Study\Software\oracle_WINDOWS.X64_193000_db_home\bin;C:\Users\imran\Downloads\WINDOWS.X64_193000_db_home\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-17\bin;D:\Study\apache-maven-3.8.4\bin;C:\Program Files\Kubernetes\Minikube;C:\Program Files\Docker\Docker\resources\bin;D:\Study\Software\helm-v3.14.0-windows-amd64\windows-amd64;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Go\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\imran\AppData\Local\Microsoft\WindowsApps;C:\Users\imran\AppData\Local\Google\Cloud SDK\google-cloud-sdk\bin;C:\Users\imran\AppData\Local\Microsoft\WinGet\Links;C:\Users\imran\go\bin;C:\Users\imran\AppData\Local\Programs\Microsoft VS Code\bin;. (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,997] INFO Client environment:java.io.tmpdir=C:\Users\imran\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,997] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,998] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,998] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,998] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,999] INFO Client environment:user.name=imran (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:35,999] INFO Client environment:user.home=C:\Users\imran (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:36,000] INFO Client environment:user.dir=D:\MyProject\Software_In_Use (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:36,000] INFO Client environment:os.memory.free=992MB (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:36,000] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:36,001] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:36,006] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@74f6c5d8 (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:40:36,114] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-04-13 18:40:36,132] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2025-04-13 18:40:36,139] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-04-13 18:40:36,151] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2025-04-13 18:40:36,158] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:54286, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-04-13 18:40:36,174] INFO Creating new log file: log.121 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2025-04-13 18:40:36,195] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, sessionid = 0x10006798a890000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-04-13 18:40:36,200] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-04-13 18:40:36,765] INFO Cluster ID = u8uSkr04TlGQZwvaBMab4w (kafka.server.KafkaServer)
[2025-04-13 18:40:36,892] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2025-04-13 18:40:36,915] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2025-04-13 18:40:36,995] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 18:40:36,997] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 18:40:36,998] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 18:40:37,081] INFO Loading logs. (kafka.log.LogManager)
[2025-04-13 18:40:37,212] INFO [Log partition=myTopic-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 6 (kafka.log.Log)
[2025-04-13 18:40:37,216] INFO [Log partition=myTopic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,242] INFO [ProducerStateManager partition=myTopic-0] Writing producer snapshot at offset 6 (kafka.log.ProducerStateManager)
[2025-04-13 18:40:37,305] INFO [Log partition=myTopic-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 6 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,315] INFO [Log partition=myTopic-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 6 and log end offset 6 in 158 ms (kafka.log.Log)
[2025-04-13 18:40:37,347] INFO [Log partition=myTopic2-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,347] INFO [Log partition=myTopic2-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,359] INFO [Log partition=myTopic2-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,361] INFO [Log partition=myTopic2-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2025-04-13 18:40:37,374] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,375] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,389] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2025-04-13 18:40:37,410] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,413] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2025-04-13 18:40:37,435] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 68 ms (kafka.log.Log)
[2025-04-13 18:40:37,447] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,447] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,455] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,457] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2025-04-13 18:40:37,470] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,470] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,480] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,483] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2025-04-13 18:40:37,492] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,493] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,501] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,503] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2025-04-13 18:40:37,512] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,513] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,521] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,523] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2025-04-13 18:40:37,532] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,533] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,545] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,547] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2025-04-13 18:40:37,556] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,556] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,566] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,567] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2025-04-13 18:40:37,579] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,580] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,593] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,595] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2025-04-13 18:40:37,604] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,605] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,612] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,614] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:37,622] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,623] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,631] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,633] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2025-04-13 18:40:37,640] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,641] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,649] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,652] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2025-04-13 18:40:37,660] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,661] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,670] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,672] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2025-04-13 18:40:37,681] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,681] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,689] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,692] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2025-04-13 18:40:37,701] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,702] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,711] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,714] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2025-04-13 18:40:37,721] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,722] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,731] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,733] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2025-04-13 18:40:37,740] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,741] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,749] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,751] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2025-04-13 18:40:37,759] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,760] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,768] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,770] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2025-04-13 18:40:37,777] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,778] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,785] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,787] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:37,795] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,795] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,806] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,808] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2025-04-13 18:40:37,816] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,816] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,841] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,844] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2025-04-13 18:40:37,854] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,855] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,864] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,866] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2025-04-13 18:40:37,873] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,874] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,881] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,883] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:37,894] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,895] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,903] INFO [ProducerStateManager partition=__consumer_offsets-29] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2025-04-13 18:40:37,911] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,913] INFO [ProducerStateManager partition=__consumer_offsets-29] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-29\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2025-04-13 18:40:37,916] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 30 ms (kafka.log.Log)
[2025-04-13 18:40:37,922] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,923] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,932] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,934] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2025-04-13 18:40:37,940] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,940] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,949] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,950] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:37,959] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:37,960] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,968] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:37,970] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2025-04-13 18:40:37,979] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2025-04-13 18:40:37,981] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.index (kafka.log.Log)
[2025-04-13 18:40:37,982] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2025-04-13 18:40:37,983] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.log (kafka.log.Log)
[2025-04-13 18:40:37,986] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.log (kafka.log.Log)
[2025-04-13 18:40:37,992] ERROR [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Could not find offset index file corresponding to log file D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2025-04-13 18:40:37,994] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,003] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2025-04-13 18:40:38,007] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 11 (kafka.log.Log)
[2025-04-13 18:40:38,008] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,010] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2025-04-13 18:40:38,020] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 12 (kafka.log.ProducerStateManager)
[2025-04-13 18:40:38,028] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 12 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,030] INFO [ProducerStateManager partition=__consumer_offsets-32] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000012.snapshot' (kafka.log.ProducerStateManager)
[2025-04-13 18:40:38,033] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 12 in 60 ms (kafka.log.Log)
[2025-04-13 18:40:38,040] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,041] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,049] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,050] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:38,058] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,059] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,066] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,068] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:38,074] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,075] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,084] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,086] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2025-04-13 18:40:38,092] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,093] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,100] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,102] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:38,108] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,108] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,116] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,118] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:38,123] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,124] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,133] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,134] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:38,140] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,140] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,147] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,149] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2025-04-13 18:40:38,157] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,157] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,166] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,168] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2025-04-13 18:40:38,174] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,174] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,182] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,183] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2025-04-13 18:40:38,189] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,190] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,199] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,200] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:38,206] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,207] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,214] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,216] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:38,222] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,222] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,230] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,232] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:38,236] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,237] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,245] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,247] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2025-04-13 18:40:38,253] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,253] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,260] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,262] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2025-04-13 18:40:38,266] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,268] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,275] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,277] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2025-04-13 18:40:38,281] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,282] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,289] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,291] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2025-04-13 18:40:38,297] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,298] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,306] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,308] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:40:38,317] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,317] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,326] INFO [ProducerStateManager partition=__consumer_offsets-49] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2025-04-13 18:40:38,335] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,337] INFO [ProducerStateManager partition=__consumer_offsets-49] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-49\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2025-04-13 18:40:38,339] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 29 ms (kafka.log.Log)
[2025-04-13 18:40:38,346] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,347] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,353] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,355] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2025-04-13 18:40:38,361] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,361] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,369] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,370] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2025-04-13 18:40:38,375] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,376] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,382] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,385] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2025-04-13 18:40:38,393] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,393] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,399] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,401] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2025-04-13 18:40:38,406] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2025-04-13 18:40:38,407] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,414] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:40:38,416] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2025-04-13 18:40:38,421] INFO Logs loading complete in 1339 ms. (kafka.log.LogManager)
[2025-04-13 18:40:38,445] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-04-13 18:40:38,449] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-04-13 18:40:38,961] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:403)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
	at java.base/java.nio.file.Files.move(Files.java:1432)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:834)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:207)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:497)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2269)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2269)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2269)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:594)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:317)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:293)
		at java.base/java.nio.file.Files.move(Files.java:1432)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:831)
		... 15 more
[2025-04-13 18:40:39,046] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,095] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,150] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,201] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,246] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,289] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,355] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,404] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,450] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,494] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,546] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,563] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2025-04-13 18:40:39,594] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,641] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,683] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,721] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,762] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,775] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2025-04-13 18:40:39,786] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2025-04-13 18:40:39,804] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,840] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,875] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,909] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,946] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:39,983] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:40,013] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 18:40:40,024] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:40,026] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 18:40:40,026] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 18:40:40,025] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 18:40:40,066] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:40,084] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-04-13 18:40:40,090] WARN [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2025-04-13 18:40:40,126] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:40,152] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2025-04-13 18:40:40,157] WARN Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2025-04-13 18:40:40,181] ERROR Failed to clean up log for __consumer_offsets-32 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-32\00000000000000000000.timeindex.cleaned: The process cannot access the file because it is being used by another process
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.implDelete(WindowsFileSystemProvider.java:275)
	at java.base/sun.nio.fs.AbstractFileSystemProvider.deleteIfExists(AbstractFileSystemProvider.java:110)
	at java.base/java.nio.file.Files.deleteIfExists(Files.java:1191)
	at kafka.log.Log$.deleteFileIfExists(Log.scala:2546)
	at kafka.log.LogSegment$.deleteIfExists(LogSegment.scala:669)
	at kafka.log.LogCleaner$.createNewCleanedSegment(LogCleaner.scala:435)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:547)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:519)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:518)
	at kafka.log.Cleaner.clean(LogCleaner.scala:492)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:361)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:334)
	at kafka.log.LogCleaner$CleanerThread.tryCleanFilthiestLog(LogCleaner.scala:314)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:303)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2025-04-13 18:40:40,181] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2025-04-13 18:40:40,710] WARN Exception causing close of session 0x10006798a890000: Connection reset (org.apache.zookeeper.server.NIOServerCnxn)
[2025-04-13 18:40:59,298] INFO Expiring session 0x10006798a890000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,203] INFO Reading configuration from: D:\MyProject\Software_In_Use\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:43:25,207] WARN \tmp\zookeeper is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:43:25,207] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:43:25,207] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:43:25,207] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-04-13 18:43:25,207] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-04-13 18:43:25,207] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2025-04-13 18:43:25,207] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2025-04-13 18:43:25,219] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2025-04-13 18:43:25,252] INFO Reading configuration from: D:\MyProject\Software_In_Use\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:43:25,252] WARN \tmp\zookeeper is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:43:25,252] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:43:25,252] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2025-04-13 18:43:25,252] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2025-04-13 18:43:25,259] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-04-13 18:43:25,287] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,287] INFO Server environment:host.name=LENOVO.mshome.net (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,287] INFO Server environment:java.version=17.0.12 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,289] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,289] INFO Server environment:java.home=C:\Program Files\Java\jdk-17 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,289] INFO Server environment:java.class.path=D:\MyProject\Software_In_Use\kafka\libs\activation-1.1.1.jar;D:\MyProject\Software_In_Use\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\argparse4j-0.7.0.jar;D:\MyProject\Software_In_Use\kafka\libs\audience-annotations-0.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\commons-cli-1.4.jar;D:\MyProject\Software_In_Use\kafka\libs\commons-lang3-3.8.1.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-api-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-file-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-json-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-mirror-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-mirror-client-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-runtime-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-transforms-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\hk2-api-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\hk2-locator-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\hk2-utils-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-annotations-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-core-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-databind-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-module-scala_2.12-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.inject-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\MyProject\Software_In_Use\kafka\libs\javassist-3.22.0-CR2.jar;D:\MyProject\Software_In_Use\kafka\libs\javassist-3.26.0-GA.jar;D:\MyProject\Software_In_Use\kafka\libs\javax.servlet-api-3.1.0.jar;D:\MyProject\Software_In_Use\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\MyProject\Software_In_Use\kafka\libs\jaxb-api-2.3.0.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-client-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-common-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-container-servlet-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-hk2-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-media-jaxb-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-server-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jopt-simple-5.0.4.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-clients-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-scala_2.12-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-tools-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-javadoc.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-javadoc.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-scaladoc.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-scaladoc.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-sources.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-sources.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test-sources.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test-sources.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\log4j-1.2.17.jar;D:\MyProject\Software_In_Use\kafka\libs\lz4-java-1.7.1.jar;D:\MyProject\Software_In_Use\kafka\libs\maven-artifact-3.6.3.jar;D:\MyProject\Software_In_Use\kafka\libs\metrics-core-2.2.0.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-codec-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-common-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-handler-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-transport-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\MyProject\Software_In_Use\kafka\libs\paranamer-2.8.jar;D:\MyProject\Software_In_Use\kafka\libs\plexus-utils-3.2.1.jar;D:\MyProject\Software_In_Use\kafka\libs\reflections-0.9.12.jar;D:\MyProject\Software_In_Use\kafka\libs\rocksdbjni-5.18.3.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-collection-compat_2.12-2.1.3.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-java8-compat_2.12-0.9.0.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-library-2.12.10.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-logging_2.12-3.9.2.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-reflect-2.12.10.jar;D:\MyProject\Software_In_Use\kafka\libs\slf4j-api-1.7.30.jar;D:\MyProject\Software_In_Use\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\MyProject\Software_In_Use\kafka\libs\snappy-java-1.1.7.3.jar;D:\MyProject\Software_In_Use\kafka\libs\validation-api-2.0.1.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\zookeeper-3.5.7.jar;D:\MyProject\Software_In_Use\kafka\libs\zookeeper-jute-3.5.7.jar;D:\MyProject\Software_In_Use\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,289] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-17\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Player\bin\;D:\Study\Software\oracle_WINDOWS.X64_193000_db_home\bin;C:\Users\imran\Downloads\WINDOWS.X64_193000_db_home\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-17\bin;D:\Study\apache-maven-3.8.4\bin;C:\Program Files\Kubernetes\Minikube;C:\Program Files\Docker\Docker\resources\bin;D:\Study\Software\helm-v3.14.0-windows-amd64\windows-amd64;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Go\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\imran\AppData\Local\Microsoft\WindowsApps;C:\Users\imran\AppData\Local\Google\Cloud SDK\google-cloud-sdk\bin;C:\Users\imran\AppData\Local\Microsoft\WinGet\Links;C:\Users\imran\go\bin;C:\Users\imran\AppData\Local\Programs\Microsoft VS Code\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,289] INFO Server environment:java.io.tmpdir=C:\Users\imran\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,289] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,289] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,289] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,289] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,289] INFO Server environment:user.name=imran (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,289] INFO Server environment:user.home=C:\Users\imran (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,289] INFO Server environment:user.dir=D:\MyProject\Software_In_Use (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,294] INFO Server environment:os.memory.free=497MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,294] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,294] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,298] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,298] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,298] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir \tmp\zookeeper\version-2 snapdir \tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2025-04-13 18:43:25,439] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2025-04-13 18:43:25,455] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 16 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-04-13 18:43:25,455] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2025-04-13 18:43:25,506] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2025-04-13 18:43:25,513] INFO Reading snapshot \tmp\zookeeper\version-2\snapshot.120 (org.apache.zookeeper.server.persistence.FileSnap)
[2025-04-13 18:43:25,576] INFO Snapshotting: 0x12f to \tmp\zookeeper\version-2\snapshot.12f (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2025-04-13 18:43:25,630] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2025-04-13 18:43:35,895] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2025-04-13 18:43:36,695] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2025-04-13 18:43:36,809] INFO starting (kafka.server.KafkaServer)
[2025-04-13 18:43:36,812] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2025-04-13 18:43:36,850] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2025-04-13 18:43:36,868] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,868] INFO Client environment:host.name=LENOVO.mshome.net (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,869] INFO Client environment:java.version=17.0.12 (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,869] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,869] INFO Client environment:java.home=C:\Program Files\Java\jdk-17 (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,870] INFO Client environment:java.class.path=D:\MyProject\Software_In_Use\kafka\libs\activation-1.1.1.jar;D:\MyProject\Software_In_Use\kafka\libs\aopalliance-repackaged-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\argparse4j-0.7.0.jar;D:\MyProject\Software_In_Use\kafka\libs\audience-annotations-0.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\commons-cli-1.4.jar;D:\MyProject\Software_In_Use\kafka\libs\commons-lang3-3.8.1.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-api-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-basic-auth-extension-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-file-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-json-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-mirror-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-mirror-client-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-runtime-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\connect-transforms-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\hk2-api-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\hk2-locator-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\hk2-utils-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-annotations-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-core-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-databind-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-dataformat-csv-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-datatype-jdk8-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-jaxrs-base-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-jaxrs-json-provider-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-module-jaxb-annotations-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-module-paranamer-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jackson-module-scala_2.12-2.10.2.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.annotation-api-1.3.4.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.inject-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.ws.rs-api-2.1.5.jar;D:\MyProject\Software_In_Use\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\MyProject\Software_In_Use\kafka\libs\javassist-3.22.0-CR2.jar;D:\MyProject\Software_In_Use\kafka\libs\javassist-3.26.0-GA.jar;D:\MyProject\Software_In_Use\kafka\libs\javax.servlet-api-3.1.0.jar;D:\MyProject\Software_In_Use\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\MyProject\Software_In_Use\kafka\libs\jaxb-api-2.3.0.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-client-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-common-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-container-servlet-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-container-servlet-core-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-hk2-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-media-jaxb-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jersey-server-2.28.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-client-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-continuation-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-http-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-io-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-security-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-server-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-servlet-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-servlets-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jetty-util-9.4.24.v20191120.jar;D:\MyProject\Software_In_Use\kafka\libs\jopt-simple-5.0.4.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-clients-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-log4j-appender-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-examples-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-scala_2.12-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-streams-test-utils-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka-tools-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-javadoc.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-javadoc.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-scaladoc.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-scaladoc.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-sources.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-sources.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test-sources.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test-sources.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0-test.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0.jar;D:\MyProject\Software_In_Use\kafka\libs\kafka_2.12-2.5.0.jar.asc;D:\MyProject\Software_In_Use\kafka\libs\log4j-1.2.17.jar;D:\MyProject\Software_In_Use\kafka\libs\lz4-java-1.7.1.jar;D:\MyProject\Software_In_Use\kafka\libs\maven-artifact-3.6.3.jar;D:\MyProject\Software_In_Use\kafka\libs\metrics-core-2.2.0.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-buffer-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-codec-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-common-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-handler-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-resolver-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-transport-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-transport-native-epoll-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\netty-transport-native-unix-common-4.1.45.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\osgi-resource-locator-1.0.1.jar;D:\MyProject\Software_In_Use\kafka\libs\paranamer-2.8.jar;D:\MyProject\Software_In_Use\kafka\libs\plexus-utils-3.2.1.jar;D:\MyProject\Software_In_Use\kafka\libs\reflections-0.9.12.jar;D:\MyProject\Software_In_Use\kafka\libs\rocksdbjni-5.18.3.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-collection-compat_2.12-2.1.3.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-java8-compat_2.12-0.9.0.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-library-2.12.10.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-logging_2.12-3.9.2.jar;D:\MyProject\Software_In_Use\kafka\libs\scala-reflect-2.12.10.jar;D:\MyProject\Software_In_Use\kafka\libs\slf4j-api-1.7.30.jar;D:\MyProject\Software_In_Use\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\MyProject\Software_In_Use\kafka\libs\snappy-java-1.1.7.3.jar;D:\MyProject\Software_In_Use\kafka\libs\validation-api-2.0.1.Final.jar;D:\MyProject\Software_In_Use\kafka\libs\zookeeper-3.5.7.jar;D:\MyProject\Software_In_Use\kafka\libs\zookeeper-jute-3.5.7.jar;D:\MyProject\Software_In_Use\kafka\libs\zstd-jni-1.4.4-7.jar (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,871] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-17\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\VMware\VMware Player\bin\;D:\Study\Software\oracle_WINDOWS.X64_193000_db_home\bin;C:\Users\imran\Downloads\WINDOWS.X64_193000_db_home\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-17\bin;D:\Study\apache-maven-3.8.4\bin;C:\Program Files\Kubernetes\Minikube;C:\Program Files\Docker\Docker\resources\bin;D:\Study\Software\helm-v3.14.0-windows-amd64\windows-amd64;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Go\bin;C:\Program Files\MySQL\MySQL Shell 8.0\bin\;C:\Users\imran\AppData\Local\Microsoft\WindowsApps;C:\Users\imran\AppData\Local\Google\Cloud SDK\google-cloud-sdk\bin;C:\Users\imran\AppData\Local\Microsoft\WinGet\Links;C:\Users\imran\go\bin;C:\Users\imran\AppData\Local\Programs\Microsoft VS Code\bin;. (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,872] INFO Client environment:java.io.tmpdir=C:\Users\imran\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,872] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,873] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,873] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,873] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,874] INFO Client environment:user.name=imran (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,874] INFO Client environment:user.home=C:\Users\imran (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,875] INFO Client environment:user.dir=D:\MyProject\Software_In_Use (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,875] INFO Client environment:os.memory.free=992MB (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,875] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,876] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,881] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@74f6c5d8 (org.apache.zookeeper.ZooKeeper)
[2025-04-13 18:43:36,971] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2025-04-13 18:43:36,984] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2025-04-13 18:43:36,990] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2025-04-13 18:43:37,002] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2025-04-13 18:43:37,009] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:54410, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2025-04-13 18:43:37,022] INFO Creating new log file: log.130 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2025-04-13 18:43:37,045] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, sessionid = 0x100067c92a10000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2025-04-13 18:43:37,051] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2025-04-13 18:43:37,587] INFO Cluster ID = u8uSkr04TlGQZwvaBMab4w (kafka.server.KafkaServer)
[2025-04-13 18:43:37,596] WARN No meta.properties file under dir D:\tmp\kafka-logs2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2025-04-13 18:43:37,723] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2025-04-13 18:43:37,744] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.5-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.5-IV0
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2025-04-13 18:43:37,802] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 18:43:37,802] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 18:43:37,826] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 18:43:37,895] INFO Log directory D:\tmp\kafka-logs2 not found, creating it. (kafka.log.LogManager)
[2025-04-13 18:43:37,914] INFO Loading logs. (kafka.log.LogManager)
[2025-04-13 18:43:37,933] INFO Logs loading complete in 18 ms. (kafka.log.LogManager)
[2025-04-13 18:43:37,963] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2025-04-13 18:43:37,970] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2025-04-13 18:43:38,797] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2025-04-13 18:43:38,898] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2025-04-13 18:43:38,901] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2025-04-13 18:43:38,951] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 18:43:38,953] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 18:43:38,955] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 18:43:38,956] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 18:43:38,984] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-04-13 18:43:39,074] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2025-04-13 18:43:39,132] INFO Stat of the created znode at /brokers/ids/0 is: 318,318,1744550019110,1744550019110,1,0,0,72064726143664128,204,0,318
 (kafka.zk.KafkaZkClient)
[2025-04-13 18:43:39,134] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(LENOVO.mshome.net,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 318 (kafka.zk.KafkaZkClient)
[2025-04-13 18:43:39,322] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 18:43:39,346] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 18:43:39,350] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 18:43:39,465] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2025-04-13 18:43:39,470] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2025-04-13 18:43:39,504] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 35 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:39,540] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:6000,blockEndProducerId:6999) by writing to Zk with path version 7 (kafka.coordinator.transaction.ProducerIdManager)
[2025-04-13 18:43:39,603] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-04-13 18:43:39,606] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-04-13 18:43:39,606] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-04-13 18:43:39,727] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 18:43:39,849] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-04-13 18:43:39,956] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2025-04-13 18:43:40,017] INFO Kafka version: 2.5.0 (org.apache.kafka.common.utils.AppInfoParser)
[2025-04-13 18:43:40,017] INFO Kafka commitId: 66563e712b0b9f84 (org.apache.kafka.common.utils.AppInfoParser)
[2025-04-13 18:43:40,018] INFO Kafka startTimeMs: 1744550019963 (org.apache.kafka.common.utils.AppInfoParser)
[2025-04-13 18:43:40,029] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2025-04-13 18:43:40,532] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, myTopic2-0, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, myTopic-0, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2025-04-13 18:43:40,737] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:40,751] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 131 ms (kafka.log.Log)
[2025-04-13 18:43:40,757] INFO Created log for partition __consumer_offsets-0 in D:\tmp\kafka-logs2\__consumer_offsets-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:40,762] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2025-04-13 18:43:40,765] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:40,768] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:40,812] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:40,814] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:40,816] INFO Created log for partition __consumer_offsets-29 in D:\tmp\kafka-logs2\__consumer_offsets-29 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:40,817] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2025-04-13 18:43:40,817] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:40,818] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:40,835] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:40,837] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:40,838] INFO Created log for partition __consumer_offsets-48 in D:\tmp\kafka-logs2\__consumer_offsets-48 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:40,839] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2025-04-13 18:43:40,840] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:40,840] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:40,855] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:40,858] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2025-04-13 18:43:40,861] INFO Created log for partition __consumer_offsets-10 in D:\tmp\kafka-logs2\__consumer_offsets-10 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:40,862] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2025-04-13 18:43:40,862] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:40,862] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:40,881] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:40,883] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2025-04-13 18:43:40,884] INFO Created log for partition __consumer_offsets-45 in D:\tmp\kafka-logs2\__consumer_offsets-45 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:40,885] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2025-04-13 18:43:40,885] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:40,885] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:40,901] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:40,903] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:40,904] INFO Created log for partition __consumer_offsets-26 in D:\tmp\kafka-logs2\__consumer_offsets-26 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:40,905] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2025-04-13 18:43:40,906] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:40,906] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:40,924] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:40,926] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2025-04-13 18:43:40,928] INFO Created log for partition __consumer_offsets-7 in D:\tmp\kafka-logs2\__consumer_offsets-7 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:40,929] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2025-04-13 18:43:40,929] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:40,929] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:40,949] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:40,951] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2025-04-13 18:43:40,953] INFO Created log for partition __consumer_offsets-42 in D:\tmp\kafka-logs2\__consumer_offsets-42 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:40,953] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2025-04-13 18:43:40,954] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:40,954] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:40,970] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:40,972] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:40,974] INFO Created log for partition __consumer_offsets-4 in D:\tmp\kafka-logs2\__consumer_offsets-4 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:40,975] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2025-04-13 18:43:40,975] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:40,976] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:40,991] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:40,993] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:40,994] INFO Created log for partition __consumer_offsets-23 in D:\tmp\kafka-logs2\__consumer_offsets-23 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:40,995] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2025-04-13 18:43:40,995] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:40,996] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,012] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,014] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2025-04-13 18:43:41,015] INFO Created log for partition __consumer_offsets-1 in D:\tmp\kafka-logs2\__consumer_offsets-1 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,016] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2025-04-13 18:43:41,016] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,016] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,031] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,032] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,034] INFO Created log for partition __consumer_offsets-20 in D:\tmp\kafka-logs2\__consumer_offsets-20 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,035] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2025-04-13 18:43:41,035] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,035] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,051] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,053] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,055] INFO Created log for partition __consumer_offsets-39 in D:\tmp\kafka-logs2\__consumer_offsets-39 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,055] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2025-04-13 18:43:41,055] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,056] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,070] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,072] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,074] INFO Created log for partition __consumer_offsets-17 in D:\tmp\kafka-logs2\__consumer_offsets-17 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,075] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2025-04-13 18:43:41,075] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,075] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,091] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,093] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:41,094] INFO Created log for partition __consumer_offsets-36 in D:\tmp\kafka-logs2\__consumer_offsets-36 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,094] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2025-04-13 18:43:41,095] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,095] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,110] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,112] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:41,114] INFO Created log for partition __consumer_offsets-14 in D:\tmp\kafka-logs2\__consumer_offsets-14 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,114] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2025-04-13 18:43:41,115] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,115] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,132] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,134] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2025-04-13 18:43:41,136] INFO Created log for partition __consumer_offsets-33 in D:\tmp\kafka-logs2\__consumer_offsets-33 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,136] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2025-04-13 18:43:41,136] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,137] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,152] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,154] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,156] INFO Created log for partition __consumer_offsets-49 in D:\tmp\kafka-logs2\__consumer_offsets-49 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,156] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2025-04-13 18:43:41,157] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,157] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,172] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,173] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,175] INFO Created log for partition __consumer_offsets-11 in D:\tmp\kafka-logs2\__consumer_offsets-11 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,176] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2025-04-13 18:43:41,176] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,177] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,194] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,196] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2025-04-13 18:43:41,198] INFO Created log for partition __consumer_offsets-30 in D:\tmp\kafka-logs2\__consumer_offsets-30 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,198] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2025-04-13 18:43:41,199] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,199] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,215] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,216] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,218] INFO Created log for partition __consumer_offsets-46 in D:\tmp\kafka-logs2\__consumer_offsets-46 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,218] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2025-04-13 18:43:41,218] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,218] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,246] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,249] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2025-04-13 18:43:41,251] INFO Created log for partition __consumer_offsets-27 in D:\tmp\kafka-logs2\__consumer_offsets-27 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,252] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2025-04-13 18:43:41,252] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,253] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,269] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,271] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,273] INFO Created log for partition __consumer_offsets-8 in D:\tmp\kafka-logs2\__consumer_offsets-8 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,273] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2025-04-13 18:43:41,273] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,274] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,288] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,290] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,292] INFO Created log for partition __consumer_offsets-24 in D:\tmp\kafka-logs2\__consumer_offsets-24 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,292] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2025-04-13 18:43:41,293] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,293] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,310] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,312] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2025-04-13 18:43:41,314] INFO Created log for partition __consumer_offsets-43 in D:\tmp\kafka-logs2\__consumer_offsets-43 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,314] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2025-04-13 18:43:41,314] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,315] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,340] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,342] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2025-04-13 18:43:41,344] INFO Created log for partition __consumer_offsets-5 in D:\tmp\kafka-logs2\__consumer_offsets-5 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,344] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2025-04-13 18:43:41,345] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,345] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,361] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,363] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2025-04-13 18:43:41,364] INFO Created log for partition __consumer_offsets-21 in D:\tmp\kafka-logs2\__consumer_offsets-21 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,365] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2025-04-13 18:43:41,365] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,365] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,380] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,381] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:41,383] INFO Created log for partition __consumer_offsets-40 in D:\tmp\kafka-logs2\__consumer_offsets-40 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,383] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2025-04-13 18:43:41,383] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,383] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,402] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,403] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2025-04-13 18:43:41,405] INFO Created log for partition __consumer_offsets-2 in D:\tmp\kafka-logs2\__consumer_offsets-2 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,405] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2025-04-13 18:43:41,405] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,406] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,421] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,422] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,424] INFO Created log for partition __consumer_offsets-37 in D:\tmp\kafka-logs2\__consumer_offsets-37 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,425] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2025-04-13 18:43:41,425] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,425] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,441] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,443] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:41,445] INFO Created log for partition __consumer_offsets-18 in D:\tmp\kafka-logs2\__consumer_offsets-18 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,445] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2025-04-13 18:43:41,445] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,446] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,462] INFO [Log partition=myTopic-0, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,464] INFO [Log partition=myTopic-0, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2025-04-13 18:43:41,465] INFO Created log for partition myTopic-0 in D:\tmp\kafka-logs2\myTopic-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,465] INFO [Partition myTopic-0 broker=0] No checkpointed highwatermark is found for partition myTopic-0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,465] INFO [Partition myTopic-0 broker=0] Log loaded for partition myTopic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,466] INFO [Partition myTopic-0 broker=0] myTopic-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,479] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,481] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,482] INFO Created log for partition __consumer_offsets-34 in D:\tmp\kafka-logs2\__consumer_offsets-34 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,482] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2025-04-13 18:43:41,483] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,483] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,496] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,497] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2025-04-13 18:43:41,499] INFO Created log for partition __consumer_offsets-15 in D:\tmp\kafka-logs2\__consumer_offsets-15 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,499] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2025-04-13 18:43:41,499] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,499] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,512] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,514] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2025-04-13 18:43:41,516] INFO Created log for partition __consumer_offsets-12 in D:\tmp\kafka-logs2\__consumer_offsets-12 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,516] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2025-04-13 18:43:41,516] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,517] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,532] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,534] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2025-04-13 18:43:41,537] INFO Created log for partition __consumer_offsets-31 in D:\tmp\kafka-logs2\__consumer_offsets-31 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,537] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2025-04-13 18:43:41,538] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,538] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,552] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,554] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,555] INFO Created log for partition __consumer_offsets-9 in D:\tmp\kafka-logs2\__consumer_offsets-9 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,555] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2025-04-13 18:43:41,556] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,556] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,571] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,573] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:41,575] INFO Created log for partition __consumer_offsets-47 in D:\tmp\kafka-logs2\__consumer_offsets-47 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,575] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2025-04-13 18:43:41,575] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,576] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,592] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,593] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:41,595] INFO Created log for partition __consumer_offsets-19 in D:\tmp\kafka-logs2\__consumer_offsets-19 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,595] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2025-04-13 18:43:41,596] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,596] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,611] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,613] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:41,614] INFO Created log for partition __consumer_offsets-28 in D:\tmp\kafka-logs2\__consumer_offsets-28 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,615] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2025-04-13 18:43:41,615] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,615] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,629] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,631] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,632] INFO Created log for partition __consumer_offsets-38 in D:\tmp\kafka-logs2\__consumer_offsets-38 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,633] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2025-04-13 18:43:41,633] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,633] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,648] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,649] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,650] INFO Created log for partition __consumer_offsets-35 in D:\tmp\kafka-logs2\__consumer_offsets-35 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,651] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2025-04-13 18:43:41,651] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,651] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,665] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,667] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,668] INFO Created log for partition __consumer_offsets-6 in D:\tmp\kafka-logs2\__consumer_offsets-6 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,669] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2025-04-13 18:43:41,669] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,669] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,682] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,684] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,685] INFO Created log for partition __consumer_offsets-44 in D:\tmp\kafka-logs2\__consumer_offsets-44 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,685] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2025-04-13 18:43:41,685] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,686] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,700] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,702] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,703] INFO Created log for partition __consumer_offsets-25 in D:\tmp\kafka-logs2\__consumer_offsets-25 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,704] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2025-04-13 18:43:41,704] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,704] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,719] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,721] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2025-04-13 18:43:41,722] INFO Created log for partition __consumer_offsets-16 in D:\tmp\kafka-logs2\__consumer_offsets-16 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,722] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2025-04-13 18:43:41,723] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,723] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,740] INFO [Log partition=myTopic2-0, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,742] INFO [Log partition=myTopic2-0, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2025-04-13 18:43:41,743] INFO Created log for partition myTopic2-0 in D:\tmp\kafka-logs2\myTopic2-0 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,744] INFO [Partition myTopic2-0 broker=0] No checkpointed highwatermark is found for partition myTopic2-0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,744] INFO [Partition myTopic2-0 broker=0] Log loaded for partition myTopic2-0 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,745] INFO [Partition myTopic2-0 broker=0] myTopic2-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,760] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,761] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:41,763] INFO Created log for partition __consumer_offsets-22 in D:\tmp\kafka-logs2\__consumer_offsets-22 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,763] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2025-04-13 18:43:41,763] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,764] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,779] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,781] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2025-04-13 18:43:41,782] INFO Created log for partition __consumer_offsets-41 in D:\tmp\kafka-logs2\__consumer_offsets-41 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,783] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2025-04-13 18:43:41,783] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,783] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,798] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,799] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2025-04-13 18:43:41,800] INFO Created log for partition __consumer_offsets-32 in D:\tmp\kafka-logs2\__consumer_offsets-32 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,801] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2025-04-13 18:43:41,801] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,801] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,817] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,819] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:41,820] INFO Created log for partition __consumer_offsets-3 in D:\tmp\kafka-logs2\__consumer_offsets-3 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,821] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2025-04-13 18:43:41,821] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,821] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,837] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2025-04-13 18:43:41,839] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2025-04-13 18:43:41,840] INFO Created log for partition __consumer_offsets-13 in D:\tmp\kafka-logs2\__consumer_offsets-13 with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.5-IV0, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1048588, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2025-04-13 18:43:41,840] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2025-04-13 18:43:41,841] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2025-04-13 18:43:41,841] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2025-04-13 18:43:41,892] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,894] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,895] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,895] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,895] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,896] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,896] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,896] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,897] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,897] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,897] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,898] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,898] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,899] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,899] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,899] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,900] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,900] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,900] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,901] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,901] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,902] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,902] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,902] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,903] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,903] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,903] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,904] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,904] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,904] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,905] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,905] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,906] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,906] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,907] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,907] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,908] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,908] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,909] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,909] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,910] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,910] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,910] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,910] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,911] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,911] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,911] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,911] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,912] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,912] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,912] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,913] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,913] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,913] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,914] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,915] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,917] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,918] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,918] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,919] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,920] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,921] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,921] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,923] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,924] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,925] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,926] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,927] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,928] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,929] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,930] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,932] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,933] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,934] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,935] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,936] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,937] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,938] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,939] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,940] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,941] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,942] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,943] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,944] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,945] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,946] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,947] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,948] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,949] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,950] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,951] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,951] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,952] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,953] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,954] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,954] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,956] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,957] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,958] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:43:41,958] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:53:12,153] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id1 in state PreparingRebalance with old generation 0 (__consumer_offsets-32) (reason: Adding new member consumer-group_id1-2-24ea7845-0c37-416e-ac21-f8395de9ea37 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2025-04-13 18:53:12,175] INFO [GroupCoordinator 0]: Stabilized group group_id1 generation 1 (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2025-04-13 18:53:12,230] INFO [GroupCoordinator 0]: Assignment received from leader for group group_id1 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2025-04-13 18:53:39,487] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 15 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2025-04-13 18:55:58,956] INFO [GroupCoordinator 0]: Member consumer-group_id1-2-24ea7845-0c37-416e-ac21-f8395de9ea37 in group group_id1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2025-04-13 18:55:58,962] INFO [GroupCoordinator 0]: Preparing to rebalance group group_id1 in state PreparingRebalance with old generation 1 (__consumer_offsets-32) (reason: removing member consumer-group_id1-2-24ea7845-0c37-416e-ac21-f8395de9ea37 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2025-04-13 18:55:58,976] INFO [GroupCoordinator 0]: Member consumer-group_id1-3-fc443e60-c0cd-4a2a-a1a9-fae7637bed5d in group group_id1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2025-04-13 18:55:59,008] INFO [GroupCoordinator 0]: Member consumer-group_id1-1-b5424bde-d586-4da0-b2be-f9883436d055 in group group_id1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2025-04-13 18:55:59,008] INFO [GroupCoordinator 0]: Group group_id1 with generation 2 is now empty (__consumer_offsets-32) (kafka.coordinator.group.GroupCoordinator)
[2025-04-13 19:01:11,365] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2025-04-13 19:01:11,383] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2025-04-13 19:01:11,464] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2025-04-13 19:01:11,476] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-04-13 19:01:11,476] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-04-13 19:01:11,476] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2025-04-13 19:01:11,476] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2025-04-13 19:01:11,502] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2025-04-13 19:01:11,502] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2025-04-13 19:01:11,508] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2025-04-13 19:01:11,523] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:11,716] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:11,716] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:11,716] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2025-04-13 19:01:11,716] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:11,748] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:11,748] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:11,751] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-04-13 19:01:11,751] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 6000 (kafka.coordinator.transaction.ProducerIdManager)
[2025-04-13 19:01:11,751] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2025-04-13 19:01:11,751] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-04-13 19:01:11,751] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-04-13 19:01:11,751] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2025-04-13 19:01:11,764] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2025-04-13 19:01:11,771] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2025-04-13 19:01:11,771] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:11,892] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:11,892] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:11,892] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:11,972] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:11,972] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:11,972] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2025-04-13 19:01:11,972] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2025-04-13 19:01:11,972] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-04-13 19:01:11,972] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-04-13 19:01:11,972] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2025-04-13 19:01:11,972] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2025-04-13 19:01:11,988] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2025-04-13 19:01:11,988] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2025-04-13 19:01:11,988] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2025-04-13 19:01:11,988] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:12,165] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:12,165] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:12,165] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:12,374] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:12,374] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:12,376] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:12,551] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:12,551] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:12,551] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:12,582] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:12,582] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2025-04-13 19:01:12,586] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2025-04-13 19:01:12,586] INFO Shutting down. (kafka.log.LogManager)
[2025-04-13 19:01:12,757] INFO [ProducerStateManager partition=myTopic-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2025-04-13 19:01:12,835] INFO [ProducerStateManager partition=__consumer_offsets-32] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2025-04-13 19:01:12,883] INFO Shutdown complete. (kafka.log.LogManager)
[2025-04-13 19:01:12,899] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2025-04-13 19:01:13,028] INFO Session: 0x100067c92a10000 closed (org.apache.zookeeper.ZooKeeper)
[2025-04-13 19:01:13,028] INFO EventThread shut down for session: 0x100067c92a10000 (org.apache.zookeeper.ClientCnxn)
[2025-04-13 19:01:13,028] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2025-04-13 19:01:13,028] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 19:01:13,393] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 19:01:13,393] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 19:01:13,393] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 19:01:14,285] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 19:01:14,285] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 19:01:14,286] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 19:01:14,300] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 19:01:14,300] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2025-04-13 19:01:14,304] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2025-04-13 19:01:14,365] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2025-04-13 19:01:14,373] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
